{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b35a76f-8d8b-4de4-9743-279691de991b",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "A **Markov Chain** is a mathematical system that undergoes transitions from one state to another on a state space. It is a stochastic process, which means that the outcome is partially random. In a Markov Chain, the next state depends only on the current state, not the sequence of events that preceded it. This property is called the **Markov Property**.\n",
    "\n",
    "A **Markov Chain** is a discrete-time stochastic dynamical system where the next state depends only on the current state. In a Markov Chain, the dynamics can be defined as follows:\n",
    "\n",
    "$$\n",
    "s_{k+1} \\mid s_k \\sim P(s_{k+1} \\mid s_k), \\quad k = 0, 1, 2, \\dots\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- \\( s_k \\) is the state at time \\( k \\).\n",
    "- The state space is the set of all possible states.\n",
    "- \\( P(s_{k+1} \\mid s_k) \\) is the probability of transitioning to the next state \\( s_{k+1} \\) given the current state \\( s_k \\).\n",
    "\n",
    "The defining property of a Markov Chain is that the distribution of the next state depends only on the current state and not on the previous states:\n",
    "\n",
    "$$\n",
    "P(s_{k+1} \\mid s_k, s_{k-1}, s_{k-2}, \\dots, s_0) = P(s_{k+1} \\mid s_k)\n",
    "$$\n",
    "\n",
    "In simple terms, once we know the current state, the past history of states does not affect the future state.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fdb14a-5e2f-452a-a390-fa39ab42b1f0",
   "metadata": {},
   "source": [
    "### Components of a Markov Chain\n",
    "1. States: These represent possible situations. In this example, we have three states:\n",
    "- Operation (S1)\n",
    "- Obstacle (S2)\n",
    "- End of Operation (S3)\n",
    "2. Transition Probabilities: These represent the likelihood of moving from one state to another. For example, from \"Operation\" (S1) to \"Obstacle\" (S2), there is a 0.2 chance. These probabilities can be represented in a Probability Matrix.\n",
    "3. Markov Property: The next state depends only on the current state, not on how we got there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a6f240-1560-474d-9a8f-ddb2cd21287a",
   "metadata": {},
   "source": [
    "### Probability Matrix\n",
    "\n",
    "The transition probabilities between the states are often summarized in a transition matrix, where each entry represents the probability of moving from one state to another.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b17b6f85-2900-4816-b672-5f1b56c50576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Episode: ['S1', 'S3']\n"
     ]
    }
   ],
   "source": [
    "class MarkovChain:\n",
    "    def __init__(self):\n",
    "        self.states = ['S1', 'S2', 'S3']\n",
    "        self.transition_matrix = [\n",
    "            [0.7, 0.2, 0.1],\n",
    "            [0.5, 0.3, 0.2],\n",
    "            [0.0, 0.0, 1.0]\n",
    "        ]\n",
    "        \n",
    "    def next_state(self, current_state):\n",
    "        import random\n",
    "        probabilities = self.transition_matrix[current_state]\n",
    "        return random.choices([0, 1, 2], probabilities)[0]\n",
    "    \n",
    "    def run_chain(self, start_state, steps):\n",
    "        current_state = start_state\n",
    "        episode = [self.states[current_state]]\n",
    "        \n",
    "        for _ in range(steps):\n",
    "            next_state_index = self.next_state(current_state)\n",
    "            next_state = self.states[next_state_index]\n",
    "            episode.append(next_state)\n",
    "            if next_state == 'S3':  #stop in terminal state\n",
    "                break\n",
    "            current_state = next_state_index\n",
    "        \n",
    "        return episode\n",
    "\n",
    "markov_chain = MarkovChain()\n",
    "start_state = 0\n",
    "episode = markov_chain.run_chain(start_state, steps=10)\n",
    "\n",
    "print(\"Generated Episode:\", episode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de67bd66-d30e-4212-b871-21c6e33c4706",
   "metadata": {},
   "source": [
    "## Explanation of the Code\n",
    "\n",
    "- States: We define three states in the MarkovChain class: S1 (Operation), S2 (Obstacle), and S3 (End of Operation).\n",
    "- Transition Matrix: This 2D matrix defines the probabilities of moving from one state to another.\n",
    "   - For instance, from S1 (Operation), the probabilities are:\n",
    "        - 70% chance of staying in S1 (Operation),\n",
    "        - 20% chance of moving to S2 (Obstacle),\n",
    "        - 10% chance of moving to S3 (End of Operation).\n",
    "    - Similarly, from S2 (Obstacle), the probabilities are:\n",
    "        - 50% chance of moving to S1 (Operation),\n",
    "        - 30% chance of staying in S2 (Obstacle),\n",
    "        - 20% chance of moving to S3 (End of Operation).\n",
    "    - S3 is a terminal state, so the probability of staying in S3 is 100%.\n",
    "- next_state(): This function takes the current state and returns the next state based on the transition probabilities.\n",
    "- run_chain(): This function simulates an episode in the Markov Chain by starting from an initial state and taking several steps, based on the transitions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a2452d-0a75-43ea-bf5e-433e2f144d2c",
   "metadata": {},
   "outputs": [],
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
