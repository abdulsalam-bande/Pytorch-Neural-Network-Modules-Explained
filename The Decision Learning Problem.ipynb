{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9da108c-9e3c-4159-839c-67fa55de43a1",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this tutorial, we'll explore decision-making under uncertainty using reinforcement learning (RL). We'll introduce a simple 1D \"Decision Learning Problem\" where an agent must find the best actions (go left or right) to maximize its rewards while considering uncertainty. This will demonstrate how RL concepts can be applied in a wide range of fields, such as robotics, autonomous systems, medicine, finance, language, and vision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c06efd-b5d0-4773-8ec3-ab4c8ee8295e",
   "metadata": {},
   "source": [
    "## Decision Learning Problem\n",
    "We'll start with a simple environment:\n",
    "\n",
    "- The environment consists of 5 states (labeled 0 to 5), where 0 and 5 are terminal states.\n",
    "- The agent starts in a non-terminal state (between 1 to 4).\n",
    "- The goal is to find a policy, which maps states to actions (left or right), to maximize rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f76cf6-594a-4268-a38d-2b4d0ae309d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static Policy: {1: 'left', 2: 'left', 3: 'right', 4: 'right'}\n",
      "In state 1, taking action 'left' leads to state 0 with reward 10.\n",
      "In state 2, taking action 'left' leads to state 1 with reward 0.\n",
      "In state 3, taking action 'right' leads to state 4 with reward 0.\n",
      "In state 4, taking action 'right' leads to state 5 with reward -10.\n"
     ]
    }
   ],
   "source": [
    "class DecisionLearningProblem:\n",
    "    def __init__(self):\n",
    "        self.states = [0, 1, 2, 3, 4, 5]\n",
    "        self.actions = ['left', 'right']\n",
    "        self.terminal_states = [0, 5]\n",
    "        self.rewards = {0: 10, 5: -10}\n",
    "        \n",
    "    def is_terminal(self, state):\n",
    "        return state in self.terminal_states\n",
    "\n",
    "    def step(self, state, action):\n",
    "        if action == 'left':\n",
    "            next_state = max(0, state - 1)\n",
    "        elif action == 'right':\n",
    "            next_state = min(5, state + 1)\n",
    "        reward = self.rewards.get(next_state, 0)\n",
    "        return next_state, reward\n",
    "\n",
    "class StaticPolicy:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.policy = {1: 'left', 2: 'left', 3: 'right', 4: 'right'}\n",
    "    \n",
    "    def show_policy(self):\n",
    "        print(\"Static Policy:\", self.policy)\n",
    "\n",
    "env = DecisionLearningProblem()\n",
    "policy = StaticPolicy(env)\n",
    "policy.show_policy()\n",
    "\n",
    "for state in range(1, 5):\n",
    "    action = policy.policy[state]\n",
    "    next_state, reward = env.step(state, action)\n",
    "    print(f\"In state {state}, taking action '{action}' leads to state {next_state} with reward {reward}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498a4e65-6479-47a8-baa9-335cabb2dc4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
